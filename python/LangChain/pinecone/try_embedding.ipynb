{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.document_loaders import ReadTheDocsLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('p50k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('./txt/01-1.txt')\n",
    "documents = loader.load()\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d62ab60f91b432f95b2cd2872bb20a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/759 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(docs)):\n",
    "    #texts = text_splitter.split_text(record.page_content)\n",
    "    uuid_value = uuid4()\n",
    "    chunks.extend([{\n",
    "        \n",
    "        'id': str(uuid_value),\n",
    "        'text': record.page_content,\n",
    "        'chunk': idx,\n",
    "        'source':record.metadata['source']\n",
    "        \n",
    "    } ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize openai API key\n",
    "openai.api_key = openai_api_key  #platform.openai.com\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "index_name = 'try_langchain_tools'\n",
    "\n",
    "# initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=pinecone_api_key,  # app.pinecone.io (console)\n",
    "    environment=\"us-central1-gcp\"  # next to API key in console\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 759}},\n",
       " 'total_vector_count': 759}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:31<00:00, 11.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk'],\n",
    "        'source': x['source']\n",
    "        \n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"赫羅喜歡吃什麼 ?\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=5, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
    "user questions based on the information provided by the user above\n",
    "each question. If the information can not be found in the information\n",
    "provided by the user you truthfully say \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "根據提供的文本，赫蘿喜歡吃隻果，但她也嘗試了羅倫斯提供的黑麥面包。至於其他食物方面的偏好並沒有提到。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': 'a388acbf-3a45-4131-84af-0880b692fb7c',\n",
      "              'metadata': {'chunk': 241.0,\n",
      "                           'source': './txt/01-1.txt',\n",
      "                           'text': '赫蘿拉了拉羅倫斯的衣服，指著攤販說。 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    在往返不斷的馬車和行人的另一邊，有著堆積如山的隻果。 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    「喔，很漂亮的隻果。」 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    「是吧!」 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    '\n",
      "                                   '外套底下的赫蘿露出閃耀著光芒的眼神。不曉得赫蘿本人有沒有察覺.她藏在腰巾里頭的尾巴正像狗兒一樣發出唰唰唰的聲音。或許赫蘿是真的喜歡吃隻果，「看起來很好吃的樣子，是吧?」 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    「是啊。」'},\n",
      "              'score': 0.854759574,\n",
      "              'values': []},\n",
      "             {'id': '110d7991-7a3e-49fa-afde-74df2a7feb51',\n",
      "              'metadata': {'chunk': 453.0,\n",
      "                           'source': './txt/01-1.txt',\n",
      "                           'text': '羅倫斯笑著說，並告訴赫蘿桌上有面包。那是用黑麥做成的黑面包。它又硬又苦.是等級最差的便宜貨，不過羅倫斯卻因為喜歡它的苦澀味而經常買來吃。 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    '\n",
      "                                   '不出所料，赫蘿咬了一口後，便抱怨起面包難吃，但因為沒有其他食物可吃，也只能認了。 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    「有沒有喝的……」 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    「那兒不是有水壺嗎?」 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    赫蘿朝放在面包旁邊的水壺里頭望了望.然後一邊喝水配面包，一邊貼近羅倫斯。'},\n",
      "              'score': 0.854423404,\n",
      "              'values': []},\n",
      "             {'id': 'bdcaa438-04c7-430d-9f6f-68816a4b5e20',\n",
      "              'metadata': {'chunk': 180.0,\n",
      "                           'source': './txt/01-1.txt',\n",
      "                           'text': '「恩，感恩，不過，還是吃飯先!」 \\n'\n",
      "                                   ' \\n'\n",
      "                                   '    '\n",
      "                                   '赫蘿隨便把皮袋及皮繩放在旁邊，那動作之草率讓羅倫斯嚇了一跳。赫蘿一副口水直流的表晴，把手伸向馬鈐薯。看來，吃飯對赫蘿來說似乎比什麼都重要。'},\n",
      "              'score': 0.854086936,\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n"
     ]
    }
   ],
   "source": [
    "ans_sample = index.query(xq, top_k=3, include_metadata=True)\n",
    "print(ans_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "赫羅喜歡吃各式各樣的食物，尤其是墨西哥菜和中國菜。\n"
     ]
    }
   ],
   "source": [
    "print(llm(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
